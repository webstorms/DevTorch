{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe48dc5a-ef97-461a-82d5-69876781be0c",
   "metadata": {},
   "source": [
    "### Goal\n",
    "This code example shows you how to train your model with an L1 or L2 penalty on all or some of its weights. Regularization is particularly important when training models on smaller datasets where models are more likely to overfit the training data. Here weight regularization can help to prevent overfitting and increase the likelihood of the model generalizing to new unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e4f0ab3-b30f-4892-854b-34647b843f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import devtorch\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb99e371-f95e-42e1-87d4-70809708a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNClassifier(devtorch.DevModel):\n",
    "    \n",
    "    def __init__(self, n_in, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(n_in, n_hidden, bias=False)\n",
    "        self.layer2 = nn.Linear(n_hidden, n_out, bias=False)\n",
    "        self.init_weight(self.layer1.weight, \"glorot_uniform\")\n",
    "        self.init_weight(self.layer2.weight, \"glorot_uniform\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.layer1(x.flatten(1, 3)))\n",
    "        return F.leaky_relu(self.layer2(x))\n",
    "    \n",
    "    # We create a function for the trainer to query the list of weights to regularize\n",
    "    def get_params_to_regularize(self):    \n",
    "        return [self.layer1.weight, self.layer2.weight]  # <= Add any number of weights you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a460107-2076-4f7e-9356-1904d6563162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:trainer:Completed epoch 0 with loss 161.70190712809563 in 7.9183s\n",
      "INFO:trainer:Completed epoch 1 with loss 66.76015388965607 in 7.8260s\n",
      "INFO:trainer:Completed epoch 2 with loss 49.29641507565975 in 7.8815s\n",
      "INFO:trainer:Completed epoch 3 with loss 42.48477016761899 in 7.8142s\n",
      "INFO:trainer:Completed epoch 4 with loss 40.64281286671758 in 7.8393s\n",
      "INFO:trainer:Completed epoch 5 with loss 41.481686882674694 in 7.8129s\n",
      "INFO:trainer:Completed epoch 6 with loss 40.89248041063547 in 7.8094s\n",
      "INFO:trainer:Completed epoch 7 with loss 36.84841175749898 in 7.8102s\n",
      "INFO:trainer:Completed epoch 8 with loss 35.3649190030992 in 7.8085s\n",
      "INFO:trainer:Completed epoch 9 with loss 33.943525440990925 in 7.8092s\n"
     ]
    }
   ],
   "source": [
    "model = ANNClassifier(784, 4000, 10)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = datasets.MNIST(\"../../data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(\"../../data\", train=False, download=True, transform=transform)\n",
    "\n",
    "regulirization_lambda = 10 ** -6\n",
    "\n",
    "def loss(output, target, model):\n",
    "    classification_loss = F.cross_entropy(output, target.long())\n",
    "    regulirization_loss = 0\n",
    "    for param in model.get_params_to_regularize():\n",
    "        regulirization_loss = regulirization_loss + regulirization_lambda * torch.norm(param, p=1)  # change p=2 for L2 penalty\n",
    "    \n",
    "    return classification_loss + regulirization_loss\n",
    "\n",
    "trainer = devtorch.get_trainer(loss, model=model, train_dataset=train_dataset, n_epochs=10, batch_size=128, lr=0.001, device=\"cuda\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12bb891b-07a0-4894-afff-790d7762a2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9786999821662903\n"
     ]
    }
   ],
   "source": [
    "def eval_metric(output, target):\n",
    "    return (torch.max(output, 1)[1] == target).sum().cpu().item()\n",
    "\n",
    "scores = devtorch.compute_metric(model, test_dataset, eval_metric, batch_size=256)\n",
    "print(f\"Accuracy = {torch.Tensor(scores).sum()/len(test_dataset)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:devtorch] *",
   "language": "python",
   "name": "conda-env-devtorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
